{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install evaluate\n!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:04:25.509509Z","iopub.execute_input":"2023-10-22T08:04:25.509890Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as nnf\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration\nfrom tqdm import tqdm\nimport os\nimport sys\nimport json\nimport pandas as pd\n\nimport random\nimport evaluate\nfrom rich.table import Column, Table\nfrom rich import box\nfrom rich.console import Console\n\n# Device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Running on device: {device}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering Method","metadata":{}},{"cell_type":"markdown","source":"## Model and Tokenizer Setup","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('VietAI/vit5-base-vietnews-summarization')\nmodel = AutoModelForSeq2SeqLM.from_pretrained('VietAI/vit5-base-vietnews-summarization')","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:10.240507Z","iopub.execute_input":"2023-10-18T08:07:10.241126Z","iopub.status.idle":"2023-10-18T08:07:14.210978Z","shell.execute_reply.started":"2023-10-18T08:07:10.241096Z","shell.execute_reply":"2023-10-18T08:07:14.210226Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Dataset setup","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n\n    def __init__(\n        self, tokenizer, cluster_list, source_len=1024, target_len=500,\n        source_dir='/kaggle/input/vims-feature/12_clustering_summary.json', \n        target_dir='/kaggle/input/vims-feature/summary_data.json'\n    ):\n        self.tokenizer = tokenizer\n        self.source_len = source_len\n        self.target_len = target_len\n        self.cluster_list = cluster_list\n        with open(source_dir, 'r') as f:\n            source_data = json.load(f)\n        self.source_data = {k: source_data[k] for k in cluster_list}\n        with open(target_dir, 'r') as f:\n            target_data = json.load(f)\n        self.target_data = {k: target_data[k] for k in cluster_list}\n\n    def __len__(self):\n        \"\"\"returns the length of dataframe\"\"\"\n        return len(self.cluster_list)\n\n    def __getitem__(self, index):\n        \"\"\"return the input ids, attention masks and target ids\"\"\"\n        \n        ## Source text\n        cluster = self.cluster_list[index]\n        source_text = self.source_data[cluster]\n        target_text = self.target_data[cluster]\n        \n        ## Tokenize\n        source = self.tokenizer.batch_encode_plus(\n            [source_text],\n            max_length=self.source_len,\n            pad_to_max_length=True,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n\n        target = self.tokenizer.batch_encode_plus(\n            [target_text],\n            max_length=self.target_len,\n            pad_to_max_length=True,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n\n        source_ids = source[\"input_ids\"].squeeze()\n        source_mask = source[\"attention_mask\"].squeeze()\n        target_ids = target[\"input_ids\"].squeeze()\n        target_mask = target[\"attention_mask\"].squeeze()\n\n        return {\n            \"source_txt\": source_text,\n            \"target_txt\": target_text,\n            \"source_ids\": source_ids.to(dtype=torch.long),\n            \"source_mask\": source_mask.to(dtype=torch.long),\n            \"target_ids\": target_ids.to(dtype=torch.long),\n            \"target_mask\": target_mask.to(dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.211808Z","iopub.execute_input":"2023-10-18T08:07:14.212054Z","iopub.status.idle":"2023-10-18T08:07:14.219881Z","shell.execute_reply.started":"2023-10-18T08:07:14.212035Z","shell.execute_reply":"2023-10-18T08:07:14.219277Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = MyDataset(tokenizer, cluster_list = os.listdir('/kaggle/input/vims-feature/original_feature/original_feature/10_cluster')[:240])\nfor i, output in enumerate(dataset):\n    print(\"Source:\")\n    print(\"Source article: \\n\", output['source_txt'])\n    print(\"Source input ids length: \\n\", len(output['source_ids']))\n    print(\"Source input ids: \\n\", output['source_ids'])\n    print(\"Source attention mask: \\n\", output['source_mask'])\n    print(\"\\n\")\n    print(\"Target:\\n\")\n    print(\"Target text: \\n\", output['target_txt'])\n    print(\"Target input ids length: \\n\", len(output['target_ids']))\n    print(\"Target attention mask: \\n\", output['target_mask'])\n    if i >= 0:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.221381Z","iopub.execute_input":"2023-10-18T08:07:14.221800Z","iopub.status.idle":"2023-10-18T08:07:14.259393Z","shell.execute_reply.started":"2023-10-18T08:07:14.221778Z","shell.execute_reply":"2023-10-18T08:07:14.258759Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Source:\nSource article: \n Ông Lộc cũng cho biết, thời gian vừa qua ông có viết đơn tố cáo cán bộ UBND xã Thanh Tường vi phạm trong công tác quản lý, sử dụng tài chính liên quan đến kinh phí xây dựng trường tiểu học của xã. Hồi giữa tháng 3, ông Lộc làm đơn tố cáo UBND xã Thanh Tường sai phạm về tài chính trong việc xây dựng trường tiểu học. Tôi vào bàn ngồi, thấy anh ta đi vào, tôi nghĩ vào trả tiền. Ông Lộc lấy gói bim bim giao cho khách xong ngồi xuống ghế. Khoảng hơn 1 tiếng sau, như đã hẹn, hai người này ghé quán của ông để mua hàng là một gói bim bim. Theo lời ông Lộc, ông không rõ động cơ, mục đích của hai người lạ mặt ấy khi hành động như thế. Trong lúc ông Lộc đang loay hoay mở cửa quán, anh Nguyễn Thế Định (trú cùng xóm) chạy sang thông báo là có hai người đi xe máy đến hỏi. Chiều ngày 25-5, Công an huyện Thanh Chương đã xuống bệnh viện, nơi ông Lộc đang nằm điều trị để tiếp xúc, lấy lời khai của nạn nhân để điều tra làm rõ vụ việc. Quá bất ngờ tôi không kịp phản ứng, ngón cái bàn tay trái bị chém đứt lìa, rơi xuống nền nhà, ngón cái bàn tay phải bị chém đứt sâu nửa ngón”. Ông Lộc được mọi người đưa vào Bệnh viện Đa khoa huyện Thanh Chương, sau đó chuyển lên Bệnh viện Chấn thương chỉnh hình tỉnh Nghệ An để điều trị. Gây án xong, hai đối tượng nhảy lên xe máy bỏ chạy. Tiếp xúc với Thanh Niên, ông Lộc kể: Tối 24.5, ông và vợ đi ra quán tạp hóa của gia đình nằm cách nhà khoảng 300 m thì có 2 người lạ mặt vào quán hỏi mua hàng rồi một trong 2 người này rút dao chém vào tay ông khiến 1 ngón tay cái bị đứt lìa, ngón khác bị đứt rất sâu, sau đó họ lên xe máy bỏ đi.\nSource input ids length: \n 1024\nSource input ids: \n tensor([ 150, 1908,  259,  ...,    0,    0,    0])\nSource attention mask: \n tensor([1, 1, 1,  ..., 0, 0, 0])\n\n\nTarget:\n\nTarget text: \n Sáng 27/5, thiếu tá Trần Văn Hùng, Phó trưởng Công an huyện Thanh Chương xác nhận: Công an huyện Thanh Chương vừa nhận được đơn tố cáo của một cụ ông gần 70 tuổi về việc bị hai đối tượng lạ mặt chặt đứt ngón tay. Hiện, công an huyện đã lấy lời khai của người bị hại và tích cực điều tra, truy tìm hai đối tượng lạ mặt này. Theo đó, người bị hại là ông Nguyễn Quang Lộc (SN 1947), trú tại xóm 3, xã Thanh Tường, huyện Thanh Chương (Nghệ An). Ông Nguyễn Quang Lộc cho biết, khoảng 19h ngày 24/5, ông đi ra quán tạp hóa (cách nhà khoảng 500m) để mở quán bán hàng. Trên đường đi, ông gặp hai người đàn ông đi xe máy và hỏi ông có phải tên Lộc, chủ cửa hàng tạp hóa không và hẹn ông lát nữa tới mua hàng. Khoảng hơn 1 tiếng sau, như đã hẹn, hai người này ghé quán của ông để mua hàng là một gói bim bim. “Tôi lấy bim bim đưa cho anh ta. Tôi vào bàn ngồi, thấy anh ta đi vào, tôi nghĩ vào trả tiền. Bất ngờ anh đó rút con dao chém vào hai tay tôi đang đặt cạnh nhau trên đùi. Quá bất ngờ tôi không kịp phản ứng, ngón cái bàn tay trái bị chém đứt lìa, rơi xuống nền nhà, ngón cái bàn tay phải bị chém đứt sâu nửa ngón”. Sau khi gây án, đối tượng lạ mặt nhanh chóng bỏ chạy ra xe và được đồng bọn chở đi. Ông Lộc được hàng xóm và gia đình sơ cứu vết thương và chuyển đến Bệnh viện đa khoa huyện Thanh Chương, sau đó được chuyển đến Bệnh viện Chấn thương chỉnh hình tỉnh Nghệ An để điều trị. Hồi giữa tháng 3, ông Lộc làm đơn tố cáo UBND xã Thanh Tường sai phạm về tài chính trong việc xây dựng trường tiểu học. Theo ông Lộc, một tổ chức phi chính phủ đã tài trợ cho xã 2 tỉ đồng, nhưng xã đã chi trái nguyên tắc hơn 1 tỉ đồng. Đơn của ông đã gửi lên huyện và tỉnh.\nTarget input ids length: \n 500\nTarget attention mask: \n tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training Setup","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n# define a rich console logger\nconsole = Console(record=True)\n\n# to display dataframe in ASCII format\ndef display_df(df):\n    \"\"\"display dataframe in ASCII format\"\"\"\n\n    console = Console()\n    table = Table(\n        Column(\"source_text\", justify=\"center\"),\n        Column(\"target_text\", justify=\"center\"),\n        title=\"Sample Data\",\n        pad_edge=False,\n        box=box.ASCII,\n    )\n\n    for i, row in enumerate(df.values.tolist()):\n        table.add_row(row[0], row[1])\n\n    console.print(table)\n\n# training logger to log training progress\ntraining_logger = Table()\n\ndef resetTable():\n    global training_logger\n\n    training_logger = Table(\n    Column(\"Epoch\", justify=\"center\"),\n    Column(\"Steps\", justify=\"center\"),\n    Column(\"Loss\", justify=\"center\"),\n    title=\"Training Status\",\n    pad_edge=False,\n    box=box.ASCII,\n)\nresetTable()","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.260380Z","iopub.execute_input":"2023-10-18T08:07:14.260770Z","iopub.status.idle":"2023-10-18T08:07:14.266861Z","shell.execute_reply.started":"2023-10-18T08:07:14.260750Z","shell.execute_reply":"2023-10-18T08:07:14.266121Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def train(epoch, tokenizer, model, device, loader, optimizer):\n\n    \"\"\"\n    Function to be called for training with the parameters passed from main function\n\n    \"\"\"\n\n    model.train()\n    for _, data in enumerate(loader, 0):\n        y = data[\"target_ids\"].to(device, dtype=torch.long)\n        y_ids = y[:, :-1].contiguous()\n        lm_labels = y[:, 1:].clone().detach()\n        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n\n        outputs = model(\n            input_ids=ids,\n            attention_mask=mask,\n            decoder_input_ids=y_ids,\n            labels=lm_labels,\n        )\n        loss = outputs[0]\n\n        if _ % 20 == 0:\n            training_logger.add_row(str(epoch), str(_), str(loss))\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    console.print(training_logger)\n    resetTable()","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.267901Z","iopub.execute_input":"2023-10-18T08:07:14.268362Z","iopub.status.idle":"2023-10-18T08:07:14.279635Z","shell.execute_reply.started":"2023-10-18T08:07:14.268340Z","shell.execute_reply":"2023-10-18T08:07:14.278702Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def validate(epoch, tokenizer, model, device, loader):\n    \"\"\"\n    Function to evaluate model for predictions\n    \"\"\"\n    model.eval()\n    \n    predictions = []\n    actuals = []\n    with torch.no_grad():\n        for _, data in enumerate(loader, 0):\n            y = data['target_ids'].to(device, dtype = torch.long)\n            ids = data['source_ids'].to(device, dtype = torch.long)\n            mask = data['source_mask'].to(device, dtype = torch.long)\n        \n            generated_ids = model.generate(\n                input_ids = ids,\n                attention_mask = mask, \n                max_length=256,\n                num_beams=5,\n                repetition_penalty=2.5,\n                length_penalty=1.0,\n                early_stopping=True\n            )\n            \n            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n            \n            if _%20==0:\n                console.print(f'Completed {_}')\n            \n            predictions.extend(preds)\n            actuals.extend(target)\n\n    # print ROUGE score\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=predictions,\n                            references=actuals)\n    console.print(\"ROUGE: \", results)\n    \n    return predictions, actuals","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.280567Z","iopub.execute_input":"2023-10-18T08:07:14.281009Z","iopub.status.idle":"2023-10-18T08:07:14.291672Z","shell.execute_reply.started":"2023-10-18T08:07:14.280987Z","shell.execute_reply":"2023-10-18T08:07:14.290692Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    'seed': 719,\n    'model_arch': \"VietAI/vit5-base-vietnews-summarization\",\n    'epochs': 3,\n    'train_bs': 2,\n    'valid_bs': 2,\n    'lr': 1e-4,\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.292726Z","iopub.execute_input":"2023-10-18T08:07:14.293018Z","iopub.status.idle":"2023-10-18T08:07:14.302735Z","shell.execute_reply.started":"2023-10-18T08:07:14.292998Z","shell.execute_reply":"2023-10-18T08:07:14.302087Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def T5Trainer(output_dir=\"/kaggle/working/\"):\n\n    \"\"\"\n    T5 trainer\n    \"\"\"\n    # Set random seeds and deterministic pytorch for reproducibility\n    seed_everything(CFG['seed'])\n\n    # logging\n    console.log(f\"\"\"[Model]: Loading {CFG[\"model_arch\"]}...\\n\"\"\")\n\n    # tokenzier for encoding the text\n    tokenizer = AutoTokenizer.from_pretrained(CFG['model_arch'])\n\n    # Defining the model\n    model = AutoModelForSeq2SeqLM.from_pretrained(CFG['model_arch'])\n    model = model.to(device)\n\n    # logging\n    console.log(f\"[Data]: Reading data...\\n\")\n\n    # Creation of Dataset and Dataloader\n    global val_dataset\n    \n    cluster_list = os.listdir('/kaggle/input/vims-feature/original_feature/original_feature/10_cluster')\n    train_cluster = cluster_list[:240]\n    val_cluster = cluster_list[240:270]\n    test_cluster = cluster_list[270:]\n\n    console.print(f\"FULL Dataset: {len(cluster_list)}\")\n    console.print(f\"TRAIN Dataset: {len(train_cluster)}\")\n    console.print(f\"TEST Dataset: {len(val_cluster)}\\n\")\n\n    # Creating the Training and Validation dataset for further creation of Dataloader\n    training_set = MyDataset(\n        tokenizer,\n        train_cluster\n    )\n    val_set = MyDataset(\n        tokenizer,\n        val_cluster\n    )\n\n    # Defining the parameters for creation of dataloaders\n    train_params = {\n        \"batch_size\": CFG[\"train_bs\"],\n        \"shuffle\": True,\n        \"num_workers\": 0,\n    }\n\n    val_params = {\n        \"batch_size\": CFG[\"valid_bs\"],\n        \"shuffle\": False,\n        \"num_workers\": 0,\n    }\n\n    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n    training_loader = DataLoader(training_set, **train_params)\n    val_loader = DataLoader(val_set, **val_params)\n\n    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n    optimizer = torch.optim.Adam(\n        params=model.parameters(), lr=CFG[\"lr\"]\n    )\n\n    # Training loop\n    console.log(f\"[Initiating Fine Tuning]...\\n\")\n\n    for epoch in range(CFG[\"epochs\"]):\n        train(epoch, tokenizer, model, device, training_loader, optimizer)\n\n    console.log(f\"[Saving Model]...\\n\")\n    # Saving the model after training\n    path = os.path.join(output_dir, \"model_files\")\n    model.save_pretrained(path)\n    tokenizer.save_pretrained(path)\n\n    # evaluating test dataset\n    global final_df\n    console.log(f\"[Initiating Validation]...\\n\")\n    predictions, actuals = validate(0, tokenizer, model, device, val_loader)\n    final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n    final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\n\n    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n\n    console.log(f\"[Validation Completed.]\\n\")\n    console.print(\n        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n    )\n    console.print(\n        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n    )\n    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.303924Z","iopub.execute_input":"2023-10-18T08:07:14.304529Z","iopub.status.idle":"2023-10-18T08:07:14.313483Z","shell.execute_reply.started":"2023-10-18T08:07:14.304505Z","shell.execute_reply":"2023-10-18T08:07:14.312877Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"T5Trainer()","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:07:14.314381Z","iopub.execute_input":"2023-10-18T08:07:14.314681Z","iopub.status.idle":"2023-10-18T08:14:34.311568Z","shell.execute_reply.started":"2023-10-18T08:07:14.314661Z","shell.execute_reply":"2023-10-18T08:14:34.310838Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[08:07:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading VietAI/vit5-base-vietnews-summarization\u001b[33m...\u001b[0m                             \u001b]8;id=294561;file:///tmp/ipykernel_281/1878575375.py\u001b\\\u001b[2m1878575375.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=856630;file:///tmp/ipykernel_281/1878575375.py#10\u001b\\\u001b[2m10\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08:07:14] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading VietAI/vit5-base-vietnews-summarization<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                             <a href=\"file:///tmp/ipykernel_281/1878575375.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1878575375.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_281/1878575375.py#10\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[08:07:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                                                 \u001b]8;id=958538;file:///tmp/ipykernel_281/1878575375.py\u001b\\\u001b[2m1878575375.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=687007;file:///tmp/ipykernel_281/1878575375.py#20\u001b\\\u001b[2m20\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08:07:20] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                 <a href=\"file:///tmp/ipykernel_281/1878575375.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1878575375.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_281/1878575375.py#20\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"FULL Dataset: \u001b[1;36m300\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TRAIN Dataset: \u001b[1;36m240\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TEST Dataset: \u001b[1;36m30\u001b[0m\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                             \u001b]8;id=915863;file:///tmp/ipykernel_281/1878575375.py\u001b\\\u001b[2m1878575375.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=569616;file:///tmp/ipykernel_281/1878575375.py#67\u001b\\\u001b[2m67\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                             <a href=\"file:///tmp/ipykernel_281/1878575375.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1878575375.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_281/1878575375.py#67\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">67</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  0   |   0   | tensor(7.4429, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  20   | tensor(2.3560, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  40   | tensor(3.6459, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  60   | tensor(2.2029, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  80   | tensor(2.3175, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  100  | tensor(1.9313, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  0   |   0   | tensor(7.4429, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  20   | tensor(2.3560, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  40   | tensor(3.6459, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  60   | tensor(2.2029, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  80   | tensor(2.3175, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  100  | tensor(1.9313, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  1   |   0   | tensor(0.6652, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  20   | tensor(2.6136, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  40   | tensor(2.8551, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  60   | tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  80   | tensor(2.0939, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  100  | tensor(1.4741, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  1   |   0   | tensor(0.6652, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  20   | tensor(2.6136, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  40   | tensor(2.8551, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  60   | tensor(1.6241, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  80   | tensor(2.0939, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  100  | tensor(1.4741, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  2   |   0   | tensor(1.5620, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  20   | tensor(0.7381, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  40   | tensor(0.8287, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  60   | tensor(1.6468, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  80   | tensor(2.2914, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  100  | tensor(1.6526, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  2   |   0   | tensor(1.5620, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  20   | tensor(0.7381, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  40   | tensor(0.8287, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  60   | tensor(1.6468, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  80   | tensor(2.2914, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  100  | tensor(1.6526, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[08:13:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                                       \u001b]8;id=648453;file:///tmp/ipykernel_281/1878575375.py\u001b\\\u001b[2m1878575375.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=427071;file:///tmp/ipykernel_281/1878575375.py#72\u001b\\\u001b[2m72\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08:13:13] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                       <a href=\"file:///tmp/ipykernel_281/1878575375.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1878575375.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_281/1878575375.py#72\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[08:13:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                              \u001b]8;id=26875;file:///tmp/ipykernel_281/1878575375.py\u001b\\\u001b[2m1878575375.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=388884;file:///tmp/ipykernel_281/1878575375.py#80\u001b\\\u001b[2m80\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08:13:15] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                              <a href=\"file:///tmp/ipykernel_281/1878575375.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1878575375.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_281/1878575375.py#80\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">80</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Completed \u001b[1;36m0\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ROUGE: \n\u001b[1m{\u001b[0m\n    \u001b[32m'rouge1'\u001b[0m: \u001b[1;36m0.5070113169277028\u001b[0m,\n    \u001b[32m'rouge2'\u001b[0m: \u001b[1;36m0.3106790386355297\u001b[0m,\n    \u001b[32m'rougeL'\u001b[0m: \u001b[1;36m0.3363026941107166\u001b[0m,\n    \u001b[32m'rougeLsum'\u001b[0m: \u001b[1;36m0.3359182270810483\u001b[0m\n\u001b[1m}\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ROUGE: \n<span style=\"font-weight: bold\">{</span>\n    <span style=\"color: #008000; text-decoration-color: #008000\">'rouge1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5070113169277028</span>,\n    <span style=\"color: #008000; text-decoration-color: #008000\">'rouge2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3106790386355297</span>,\n    <span style=\"color: #008000; text-decoration-color: #008000\">'rougeL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3363026941107166</span>,\n    <span style=\"color: #008000; text-decoration-color: #008000\">'rougeLsum'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3359182270810483</span>\n<span style=\"font-weight: bold\">}</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[08:14:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                                                                 \u001b]8;id=490793;file:///tmp/ipykernel_281/1878575375.py\u001b\\\u001b[2m1878575375.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=600727;file:///tmp/ipykernel_281/1878575375.py#87\u001b\\\u001b[2m87\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08:14:34] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                                                                 <a href=\"file:///tmp/ipykernel_281/1878575375.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1878575375.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_281/1878575375.py#87\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">87</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ \u001b[35m/kaggle/working/\u001b[0m\u001b[95mmodel_files\u001b[0m\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ <span style=\"color: #800080; text-decoration-color: #800080\">/kaggle/working/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">model_files</span>\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ \u001b[35m/kaggle/working/\u001b[0m\u001b[95mpredictions.csv\u001b[0m\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ <span style=\"color: #800080; text-decoration-color: #800080\">/kaggle/working/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">predictions.csv</span>\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ \u001b[35m/kaggle/working/\u001b[0m\u001b[95mlogs.txt\u001b[0m\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ <span style=\"color: #800080; text-decoration-color: #800080\">/kaggle/working/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">logs.txt</span>\n\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Show result","metadata":{}},{"cell_type":"code","source":"rd_idx=5\n## Actual\nprint(\"Actual: \\n\")\nprint(final_df['Actual Text'][rd_idx])\nprint()\n## Prediction\nprint(\"Prediction: \\n\")\nprint(final_df['Generated Text'][rd_idx])","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:14:34.312707Z","iopub.execute_input":"2023-10-18T08:14:34.312948Z","iopub.status.idle":"2023-10-18T08:14:34.317116Z","shell.execute_reply.started":"2023-10-18T08:14:34.312926Z","shell.execute_reply":"2023-10-18T08:14:34.316405Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Actual: \n\nHãng tin AFP dẫn nguồn tin từ giới chức Nhật Bản cho biết, cậu bé Yamato Tanooka, 7 tuổi, bị mất tích sau chuyến đi chơi cùng gia đình trong một khu rừng đầy gấu ở phía bắc Nhật Bản đã được tìm thấy hôm nay 3/6. Khi được tìm thấy, cậu bé đang trong tình trạng khá tốt và không bị thương. Khu vực phát hiện cách nơi cậu bé được cho là đã mất tích khoảng 5km. Khu rừng này được cho là nơi sinh sống của khoảng 500 con gấu nâu, tuy nhiên rất may là những ngày này chúng hoạt động hạn chế do có mưa rào. Ban đầu, cha mẹ của Yamato Tanooka khai báo với cảnh sát rằng con trai họ mất tích trong lúc cả nhà đang đi dạo trong rừng và hái rau dại. Sau đó, ông Takayuki Tanooka mới thừa nhận rằng mình và vợ dừng xe trên một con đường núi, yêu cầu con trai ra ngoài để chịu phạt rồi lái xe đi. Sau khi lái xe đi khoảng 500m, họ quay lại đón con nhưng Tanooka đã biến mất.\n\nPrediction: \n\nTheo nguồn tin từ giới chức Nhật Bản, một quan chức của Lực lượng Phòng vệ Nhật Bản đã tình cờ tìm thấy cậu bé Yamato Tanooka, 7 tuổi, bị mất tích sau chuyến đi chơi cùng gia đình trong một khu rừng đầy gấu ở phía bắc Nhật Bản vào lúc 7h50 sáng nay 3/6. Nhìn bề ngoài cậu bé không bị chấn thương, nhưng cậu tự giới thiệu mình là Yamato Yamato Tanooka, cha mẹ của Yamato Tanooka cho biết. Nhìn bề ngoài cậu bé không bị chấn thương và cậu bé tự giới thiệu mình là Yamato Yamato Tanooka, người phát ngôn của lực lượng phòng vệ Nhật Bản cũng xác nhận với báo giới.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# GPT (Not complete)","metadata":{}},{"cell_type":"markdown","source":"## Dataset setup","metadata":{}},{"cell_type":"code","source":"prefix_length = 1","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:10:59.595308Z","iopub.execute_input":"2023-10-22T08:10:59.595922Z","iopub.status.idle":"2023-10-22T08:10:59.599970Z","shell.execute_reply.started":"2023-10-22T08:10:59.595894Z","shell.execute_reply":"2023-10-22T08:10:59.599132Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# class VNSummaryDataset(Dataset):\n#     def __init__(self, original_data_path, summary_data_path, cluster_list, \n#                  prefix_length, gpt2_type='NlpHUST/gpt2-vietnamese',\n#                  original_data_type='mean'):\n#         self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n#         self.prefix_length = prefix_length\n#         self.original_data_path = original_data_path\n#         self.original_data_type = original_data_type\n#         self.cluster_list = cluster_list\n#         with open(summary_data_path, 'r') as f:\n#             summary_data = json.load(f)\n#         summary_data = {k: summary_data[k] for k in cluster_list}\n#         print(\"Data size is %0d\" % len(cluster_list))\n#         sys.stdout.flush()\n#         self.summary_tokens = {}\n#         max_seq_len = 0\n#         for cluster, summary in summary_data.items():\n#             tokens = torch.tensor(self.tokenizer.encode(summary), dtype=torch.int64)\n#             self.summary_tokens[cluster] = tokens\n#             max_seq_len = max(max_seq_len, tokens.shape[0])\n#         all_len = torch.tensor([len(self.summary_tokens[i]) for i in self.summary_tokens.keys()]).float()\n#         self.max_seq_len = min(int(all_len.mean() + all_len.std() * 10), int(all_len.max()))\n\n#     def pad_tokens(self, item):\n#         tokens = self.summary_tokens[item]\n#         padding = self.max_seq_len - tokens.shape[0]\n#         if padding > 0:\n#             tokens = torch.cat((tokens, torch.zeros(padding, dtype=torch.int64) - 1))\n#             self.summary_tokens[item] = tokens\n#         elif padding < 0:\n#             tokens = tokens[:self.max_seq_len]\n#             self.summary_tokens[item] = tokens\n#         mask = tokens.ge(0)  # mask is zero where we out of sequence\n#         tokens[~mask] = 0\n#         mask = mask.float()\n#         mask = torch.cat((torch.ones(self.prefix_length), mask), dim=0)  # adding prefix mask\n#         return tokens, mask\n    \n#     def __len__(self):\n#         return len(self.cluster_list)\n\n#     def __getitem__(self, item):\n#         cluster = self.cluster_list[item]\n#         tokens, mask = self.pad_tokens(cluster)\n#         prefix = torch.from_numpy(np.load(os.path.join(self.original_data_path, cluster, '{}.npy'.format(self.original_data_type)))).to(device)\n#         return tokens, mask, prefix\n\nclass VNSummaryDataset(Dataset):\n    def __init__(self, original_data_path, summary_data_path, cluster_list, \n                 prefix_length, gpt2_type='NlpHUST/gpt2-vietnamese'):\n        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n        self.prefix_length = prefix_length\n        with open(original_data_path, 'r') as f:\n            self.prefix_data = json.load(f)\n        self.cluster_list = cluster_list\n        with open(summary_data_path, 'r') as f:\n            summary_data = json.load(f)\n        summary_data = {k: summary_data[k] for k in cluster_list}\n        print(\"Data size is %0d\" % len(cluster_list))\n        sys.stdout.flush()\n        self.summary_tokens = {}\n        max_seq_len = 0\n        for cluster, summary in summary_data.items():\n            tokens = torch.tensor(self.tokenizer.encode(summary), dtype=torch.int64)\n            self.summary_tokens[cluster] = tokens\n            max_seq_len = max(max_seq_len, tokens.shape[0])\n        all_len = torch.tensor([len(self.summary_tokens[i]) for i in self.summary_tokens.keys()]).float()\n        self.max_seq_len = min(int(all_len.mean() + all_len.std() * 10), int(all_len.max()))\n\n    def pad_tokens(self, item):\n        tokens = self.summary_tokens[item]\n        padding = self.max_seq_len - tokens.shape[0]\n        if padding > 0:\n            tokens = torch.cat((tokens, torch.zeros(padding, dtype=torch.int64) - 1))\n            self.summary_tokens[item] = tokens\n        elif padding < 0:\n            tokens = tokens[:self.max_seq_len]\n            self.summary_tokens[item] = tokens\n        mask = tokens.ge(0)  # mask is zero where we out of sequence\n        tokens[~mask] = 0\n        mask = mask.float()\n        mask = torch.cat((torch.ones(self.prefix_length), mask), dim=0)  # adding prefix mask\n        return tokens, mask\n    \n    def __len__(self):\n        return len(self.cluster_list)\n\n    def __getitem__(self, item):\n        cluster = self.cluster_list[item]\n        tokens, mask = self.pad_tokens(cluster)\n        prefix = torch.FloatTensor(self.prefix_data[cluster]).unsqueeze(0).to(device)\n        return tokens, mask, prefix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-22T08:10:59.603013Z","iopub.execute_input":"2023-10-22T08:10:59.603295Z","iopub.status.idle":"2023-10-22T08:10:59.619928Z","shell.execute_reply.started":"2023-10-22T08:10:59.603271Z","shell.execute_reply":"2023-10-22T08:10:59.619057Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = VNSummaryDataset(\n    original_data_path = '/kaggle/input/vims-feature/original_data_embedding.json', \n    summary_data_path = '/kaggle/input/vims-feature/summary_data.json',\n    cluster_list = os.listdir('/kaggle/input/vims-feature/original_feature/original_feature/10_cluster')[:240],\n    prefix_length = prefix_length\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:10:59.621197Z","iopub.execute_input":"2023-10-22T08:10:59.621534Z","iopub.status.idle":"2023-10-22T08:11:01.882403Z","shell.execute_reply.started":"2023-10-22T08:10:59.621499Z","shell.execute_reply":"2023-10-22T08:11:01.881436Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/854k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"414b5fe4e1224a9baaed15ebaf445798"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/512k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67c9f27963464c4da3dea7e876bd835e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aab323b2546d40ba968e639f06a85a8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d64b24174f24752ad2bbe2d66eaeca6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6d320e170d4788982f3c0d0dc51492"}},"metadata":{}},{"name":"stdout","text":"Data size is 240\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset[0][2].shape","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:11:01.883758Z","iopub.execute_input":"2023-10-22T08:11:01.884057Z","iopub.status.idle":"2023-10-22T08:11:07.683357Z","shell.execute_reply.started":"2023-10-22T08:11:01.884031Z","shell.execute_reply":"2023-10-22T08:11:07.682277Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 768])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Setup","metadata":{}},{"cell_type":"code","source":"class VNSummaryModel(nn.Module):\n    def __init__(self, prefix_length, prefix_size = 768):\n        super(VNSummaryModel, self).__init__()\n        self.prefix_length = prefix_length\n        self.gpt = GPT2LMHeadModel.from_pretrained('NlpHUST/gpt2-vietnamese')\n        self.gpt_embedding_size = self.gpt.transformer.wte.weight.shape[1]\n        \n    def get_dummy_token(self, batch_size, device):\n        return torch.zeros(batch_size, self.prefix_length, dtype=torch.int64, device=device)\n\n    def forward(self, tokens, prefix, mask = None, labels = None):\n        embedding_text = self.gpt.transformer.wte(tokens)\n        embedding_cat = torch.cat((prefix, embedding_text), dim=1)\n        \n        if labels is not None:\n            dummy_token = self.get_dummy_token(tokens.shape[0], tokens.device)\n            labels = torch.cat((dummy_token, tokens), dim=1)\n\n        out = self.gpt(inputs_embeds=embedding_cat, labels=labels, attention_mask=mask)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:11:07.684638Z","iopub.execute_input":"2023-10-22T08:11:07.684935Z","iopub.status.idle":"2023-10-22T08:11:07.695196Z","shell.execute_reply.started":"2023-10-22T08:11:07.684909Z","shell.execute_reply":"2023-10-22T08:11:07.694176Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2023-10-20T02:39:34.650182Z","iopub.execute_input":"2023-10-20T02:39:34.650591Z","iopub.status.idle":"2023-10-20T02:39:34.656570Z","shell.execute_reply.started":"2023-10-20T02:39:34.650562Z","shell.execute_reply":"2023-10-20T02:39:34.655267Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = VNSummaryModel(prefix_length, prefix_size=768)\nfor idx, (tokens, mask, prefix) in enumerate(dataloader):\n    model.zero_grad()\n    tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.float32)\n    outputs = model(tokens, prefix, mask)\n    logits = outputs.logits[:, 10 - 1: -1]\n    print(logits.shape)\n    print(logits.reshape(-1, logits.shape[-1]).shape)\n    print(tokens.shape)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n# define a rich console logger\nconsole = Console(record=True)\n\n# to display dataframe in ASCII format\ndef display_df(df):\n    \"\"\"display dataframe in ASCII format\"\"\"\n\n    console = Console()\n    table = Table(\n        Column(\"source_text\", justify=\"center\"),\n        Column(\"target_text\", justify=\"center\"),\n        title=\"Sample Data\",\n        pad_edge=False,\n        box=box.ASCII,\n    )\n\n    for i, row in enumerate(df.values.tolist()):\n        table.add_row(row[0], row[1])\n\n    console.print(table)\n\n# training logger to log training progress\ntraining_logger = Table()\n\ndef resetTable():\n    global training_logger\n\n    training_logger = Table(\n    Column(\"Epoch\", justify=\"center\"),\n    Column(\"Steps\", justify=\"center\"),\n    Column(\"Loss\", justify=\"center\"),\n    title=\"Training Status\",\n    pad_edge=False,\n    box=box.ASCII,\n)\nresetTable()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:11:07.696417Z","iopub.execute_input":"2023-10-22T08:11:07.696713Z","iopub.status.idle":"2023-10-22T08:11:07.712173Z","shell.execute_reply.started":"2023-10-22T08:11:07.696687Z","shell.execute_reply":"2023-10-22T08:11:07.711358Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nbatch_size = 8\nepochs = 10\noutput_dir = '/kaggle/working/result'\nlr = 2e-5\nwarmup_steps = 5000\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\nmodel = VNSummaryModel(prefix_length, prefix_size=768)\nmodel = model.to(device)\nmodel.train()\noptimizer = AdamW(model.parameters(), lr=lr)\ntrain_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, num_warmup_steps=warmup_steps, num_training_steps=epochs * len(train_dataloader)\n)\nfor epoch in range(epochs):\n    print(f\">>> Training epoch {epoch}\")\n    sys.stdout.flush()\n    for idx, (tokens, mask, prefix) in enumerate(train_dataloader, 0):\n        model.zero_grad()\n        tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.float32)\n        outputs = model(tokens, prefix, mask)\n        logits = outputs.logits[:, dataset.prefix_length - 1: -1]\n        loss = nnf.cross_entropy(logits.reshape(-1, logits.shape[-1]), tokens.flatten(), ignore_index=0)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n            \n        if idx % 5 == 0:\n            training_logger.add_row(str(epoch), str(idx), str(loss))\n    console.print(training_logger)\n    resetTable()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:11:07.714253Z","iopub.execute_input":"2023-10-22T08:11:07.714881Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4602495b6ecd4b559da5796360323b5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee223f418366488981a0c60c233d9767"}},"metadata":{}},{"name":"stdout","text":">>> Training epoch 0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  0   |   0   | tensor(2.5139, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |   5   | tensor(2.6115, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  10   | tensor(2.3515, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  15   | tensor(2.4751, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  20   | tensor(2.2523, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  0   |  25   | tensor(2.4743, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  0   |   0   | tensor(2.5139, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |   5   | tensor(2.6115, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  10   | tensor(2.3515, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  15   | tensor(2.4751, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  20   | tensor(2.2523, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  0   |  25   | tensor(2.4743, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  1   |   0   | tensor(2.5584, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |   5   | tensor(2.3508, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  10   | tensor(2.1822, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  15   | tensor(2.5398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  20   | tensor(2.4461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  1   |  25   | tensor(2.5194, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  1   |   0   | tensor(2.5584, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |   5   | tensor(2.3508, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  10   | tensor(2.1822, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  15   | tensor(2.5398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  20   | tensor(2.4461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  1   |  25   | tensor(2.5194, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  2   |   0   | tensor(2.3888, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |   5   | tensor(2.1033, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  10   | tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  15   | tensor(2.1680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  20   | tensor(2.5816, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  2   |  25   | tensor(2.4645, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  2   |   0   | tensor(2.3888, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |   5   | tensor(2.1033, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  10   | tensor(2.3250, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  15   | tensor(2.1680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  20   | tensor(2.5816, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  2   |  25   | tensor(2.4645, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  3   |   0   | tensor(2.5958, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  3   |   5   | tensor(2.3932, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  3   |  10   | tensor(2.4937, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  3   |  15   | tensor(2.3900, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  3   |  20   | tensor(2.4168, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  3   |  25   | tensor(2.4876, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  3   |   0   | tensor(2.5958, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  3   |   5   | tensor(2.3932, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  3   |  10   | tensor(2.4937, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  3   |  15   | tensor(2.3900, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  3   |  20   | tensor(2.4168, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  3   |  25   | tensor(2.4876, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  4   |   0   | tensor(2.3947, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  4   |   5   | tensor(2.5654, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  4   |  10   | tensor(2.3582, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  4   |  15   | tensor(2.5063, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  4   |  20   | tensor(2.4024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  4   |  25   | tensor(2.4194, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  4   |   0   | tensor(2.3947, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  4   |   5   | tensor(2.5654, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  4   |  10   | tensor(2.3582, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  4   |  15   | tensor(2.5063, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  4   |  20   | tensor(2.4024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  4   |  25   | tensor(2.4194, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  5   |   0   | tensor(2.3576, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  5   |   5   | tensor(2.6405, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  5   |  10   | tensor(2.3572, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  5   |  15   | tensor(2.3450, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  5   |  20   | tensor(2.3297, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  5   |  25   | tensor(2.2898, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  5   |   0   | tensor(2.3576, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  5   |   5   | tensor(2.6405, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  5   |  10   | tensor(2.3572, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  5   |  15   | tensor(2.3450, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  5   |  20   | tensor(2.3297, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  5   |  25   | tensor(2.2898, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  6   |   0   | tensor(2.6255, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  6   |   5   | tensor(2.5643, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  6   |  10   | tensor(2.3540, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  6   |  15   | tensor(2.6701, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  6   |  20   | tensor(2.4176, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  6   |  25   | tensor(2.3581, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  6   |   0   | tensor(2.6255, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  6   |   5   | tensor(2.5643, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  6   |  10   | tensor(2.3540, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  6   |  15   | tensor(2.6701, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  6   |  20   | tensor(2.4176, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  6   |  25   | tensor(2.3581, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                               Training Status                               \u001b[0m\n+---------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n|------+-------+------------------------------------------------------------|\n|  7   |   0   | tensor(2.3541, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  7   |   5   | tensor(2.6014, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  7   |  10   | tensor(2.3312, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  7   |  15   | tensor(2.3991, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  7   |  20   | tensor(2.4232, device='cuda:0', grad_fn=<NllLossBackward0>)|\n|  7   |  25   | tensor(2.6160, device='cuda:0', grad_fn=<NllLossBackward0>)|\n+---------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n+---------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n|------+-------+------------------------------------------------------------|\n|  7   |   0   | tensor(2.3541, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  7   |   5   | tensor(2.6014, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  7   |  10   | tensor(2.3312, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  7   |  15   | tensor(2.3991, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  7   |  20   | tensor(2.4232, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n|  7   |  25   | tensor(2.6160, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n+---------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"name":"stdout","text":">>> Training epoch 8\n","output_type":"stream"}]}]}